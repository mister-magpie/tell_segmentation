{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Archeo\n",
        "\n"
      ],
      "metadata": {
        "id": "2p3BQeqhpwC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Training dei modelli"
      ],
      "metadata": {
        "id": "gFEAYIshp9ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1Caricamento di path e librerie, oltre allo scheletro della configurazione del modello"
      ],
      "metadata": {
        "id": "Hxq9RgqHqEDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rich\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations import pytorch\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.callbacks import TQDMProgressBar, RichProgressBar\n",
        "\n",
        "import segmentation_models_pytorch  as smp\n",
        "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "\n",
        "PATH_LOG='/exp_logs/'\n",
        "PATH_DATASETS='/datasets/'\n",
        "modelli=['bing_1k','bing_1k_filtrato','bing+corona_1k','bing+corona_2k_filtrato',\n",
        "         'bing_2k','bing_2k_filtrato']\n",
        "testset_modelli={}\n",
        "\n",
        "config = {\n",
        "    \"timestamp\" : datetime.now().strftime(\"%d-%m-%Y_%H%M%S\"),\n",
        "    \"dataset_path\" : \"\",\n",
        "    \"checkpoint_path\":PATH_LOG,\n",
        "    \"random_seed\" : 1234,\n",
        "    \"arch\":\"MAnet\", #Unet,MAnet\n",
        "    \"encoder\":\"efficientnet-b3\", #resnet18, dpn68, efficientnet-b3\n",
        "    \"weights\":\"imagenet\",\n",
        "    \"loss\":\"focal\",\n",
        "    \"learning_rate\":0.0001,\n",
        "    \"precision\":32,\n",
        "    \"epochs\":20,\n",
        "    \"batch_size\":32,\n",
        "    \"corona_path\":\"\",\n",
        "    \"dim_input\":'',\n",
        "    \"in_channels\":0\n",
        "}\n",
        "\n",
        "random.seed(config[\"random_seed\"])\n",
        "np.random.seed(config[\"random_seed\"])\n",
        "torch.manual_seed(config[\"random_seed\"])\n"
      ],
      "metadata": {
        "id": "6ZrWVv32S8I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2 Divisione del dataset in train set (80%), validation set (10%) e test set (10%)"
      ],
      "metadata": {
        "id": "-LFnjlL2qP8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(PATH,SEED,indices):\n",
        "    root_directory = os.path.join(PATH)\n",
        "    images_directory = os.path.join(root_directory, \"train/sites\")\n",
        "    masks_directory = os.path.join(root_directory, \"train/masks\")\n",
        "    \n",
        "    filenames_train = np.asarray(list(sorted(os.listdir(images_directory))))\n",
        "    print(\"total files:\",len(filenames_train))\n",
        "\n",
        "    valid_split = -int(len(indices)*0.2)\n",
        "    test_split = valid_split//2\n",
        "    \n",
        "    train_indices = indices[:valid_split]\n",
        "    valid_indices = indices[valid_split:test_split]\n",
        "    test_indices = indices[test_split:]\n",
        "    train_images_filenames = filenames_train[train_indices]\n",
        "    val_images_filenames = filenames_train[valid_indices]\n",
        "    test_images_filenames = filenames_train[test_indices]\n",
        "\n",
        "    print(\"root:\",root_directory,\"\\nimages\",images_directory,\n",
        "          \"\\nmasks\",masks_directory,\"\\n---\",\n",
        "          '\\ntrain images',len(train_images_filenames), \n",
        "          '\\nval images',len(val_images_filenames), \n",
        "          '\\ntest images',len(test_images_filenames),\n",
        "          '\\n---\\ntotal images',len(filenames_train)\n",
        "         )\n",
        "    \n",
        "    print(\"empty masks percentage: %.4f %.4f %.4f\" % \n",
        "          (np.sum([i.startswith(\"neg\") for i in train_images_filenames])/len(train_images_filenames),\n",
        "            np.sum([i.startswith(\"neg\") for i in val_images_filenames])/len(val_images_filenames),\n",
        "            np.sum([i.startswith(\"neg\") for i in test_images_filenames])/len(test_images_filenames)\n",
        "          ))\n",
        "    \n",
        "    return images_directory, masks_directory, train_images_filenames,\n",
        "            val_images_filenames,test_images_filenames"
      ],
      "metadata": {
        "id": "oxsYae5BYFpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Crop e resize dipendono dalla dimensione dell'input \n",
        "def esegui_trasformazioni():\n",
        "  if(config[\"dim_input\"]=='1k' and config['corona_path']!=\"\"): #stesso crop per input bing e input corona\n",
        "    train_transform = A.Compose([\n",
        "            A.RandomCrop(512,512,p=1.0),\n",
        "            A.Flip(p=0.25),A.RandomRotate90(p=0.25),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.25),\n",
        "            A.Resize(256, 256),\n",
        "            A.pytorch.ToTensorV2(),\n",
        "        ],\n",
        "        additional_targets={'image_corona': 'image'})\n",
        "  \n",
        "\n",
        "    val_transform = A.Compose([\n",
        "            A.RandomCrop(512,512,p=1.0),\n",
        "            A.Resize(256, 256),\n",
        "            A.pytorch.ToTensorV2()\n",
        "        ],\n",
        "        additional_targets={'image_corona': 'image'})\n",
        "  elif(config[\"dim_input\"]=='1k' and config['corona_path']==\"\"):\n",
        "        train_transform = A.Compose([\n",
        "            A.RandomCrop(512,512,p=1.0),\n",
        "            A.Flip(p=0.25),A.RandomRotate90(p=0.25)\n",
        "            ,A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.25),\n",
        "            A.Resize(256, 256),\n",
        "            A.pytorch.ToTensorV2(),\n",
        "        ])\n",
        "     \n",
        "        val_transform = A.Compose([\n",
        "            A.RandomCrop(512,512,p=1.0),\n",
        "            A.Resize(256, 256),\n",
        "            A.pytorch.ToTensorV2()\n",
        "        ])\n",
        "\n",
        "  elif(config[\"dim_input\"]=='2k' and config['corona_path']!=\"\"):\n",
        "    train_transform = A.Compose([\n",
        "            A.RandomCrop(1024,1024,p=1.0),\n",
        "            A.Flip(p=0.25),A.RandomRotate90(p=0.25)\n",
        "            ,A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.25),\n",
        "            A.Resize(512, 512),\n",
        "            A.pytorch.ToTensorV2(),\n",
        "        ],\n",
        "        additional_targets={'image_corona': 'image'})\n",
        "  \n",
        "    val_transform = A.Compose([\n",
        "            A.RandomCrop(1024,1024,p=1.0),\n",
        "            A.Resize(512, 512),\n",
        "            A.pytorch.ToTensorV2()\n",
        "        ],\n",
        "        additional_targets={'image_corona': 'image'})\n",
        "  else:\n",
        "    train_transform = A.Compose([\n",
        "            A.RandomCrop(1024,1024,p=1.0),\n",
        "            A.Flip(p=0.25),A.RandomRotate90(p=0.25)\n",
        "            ,A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.25),\n",
        "            A.Resize(512, 512),\n",
        "            A.pytorch.ToTensorV2(),\n",
        "        ])\n",
        "  \n",
        "    val_transform = A.Compose([\n",
        "            A.RandomCrop(1024,1024,p=1.0),\n",
        "            A.Resize(512, 512),\n",
        "            A.pytorch.ToTensorV2()\n",
        "        ])\n",
        "  return train_transform,val_transform\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "M3UX56KZM6KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.3 Caricamento del dataset con le relative trasformazioni"
      ],
      "metadata": {
        "id": "VfgisvZxqlWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Carico il dataset con le relative trasformazioni, in base al tipo di modello che stiamo analizzando,\n",
        "#cioè in base alla dimensione di input di ogni immagine e ai canali di input. \n",
        "class ArcheoDataset(Dataset):\n",
        "    def __init__(self, images_filenames, images_directory, masks_directory, transform=None):\n",
        "        self.images_filenames = images_filenames\n",
        "        self.images_directory = images_directory\n",
        "        self.masks_directory = masks_directory\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images_filenames)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_filename = self.images_filenames[idx]\n",
        "        image_path = os.path.join(self.images_directory, image_filename)\n",
        "        mask_path = os.path.join(self.masks_directory, image_filename.replace(\".jpg\", \".png\"))\n",
        "        \n",
        "        image = np.array(Image.open(image_path))#.convert(\"RGB\"))\n",
        "        image = Image.open(image_path)\n",
        "      \n",
        "        \n",
        "        mask = ~np.array(Image.open(mask_path).convert(\"L\")) # masks are flipped because of qgis\n",
        "        mask = mask.astype(\"float\")\n",
        "        mask[mask > 0.0] = 1.0\n",
        "        mask = np.expand_dims(mask, -1)\n",
        "\n",
        "\n",
        "        if(config['corona_path']!=\"\"):\n",
        "          path_corona=config['corona_path']\n",
        "          image_path_corona=os.path.join(path_corona, image_filename)\n",
        "          image_corona =np.array(Image.open(image_path_corona))\n",
        "          image_corona = Image.open(image_path_corona)\n",
        "          transformed = self.transform(image=np.asarray(image),\n",
        "                                       image_corona=np.asarray(image_corona),\n",
        "                                       mask=np.asarray(mask))\n",
        "          image_corona=transformed[\"image_corona\"]\n",
        "          image = transformed[\"image\"]\n",
        "          image=torch.cat((image, image_corona), 0)\n",
        "      \n",
        "        else:\n",
        "          transformed = self.transform(image=np.asarray(image),mask=np.asarray(mask))\n",
        "          image = transformed[\"image\"]\n",
        "\n",
        "        \n",
        "        mask = transformed[\"mask\"].permute(2,0,1)\n",
        "        \n",
        "            \n",
        "        return image, mask, image_filename\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vIEBqKiVYlLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.4 Inizializzazione del modello"
      ],
      "metadata": {
        "id": "iwtR-1gPpd19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inizializzazione del modello, calcolo della funzione di loss sulla maschere, probabilità ottenute \n",
        "#con il sigmoid. Le probabilità maggiori di 0.5 vengono trasformate in 1, quelle sotto lo 0.5 in 0.  \n",
        "class ArcheoModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, arch, encoder_name, in_channels, out_classes, **kwargs):\n",
        "        super().__init__()\n",
        "        self.model = smp.create_model(\n",
        "            arch, encoder_name=encoder_name, in_channels=in_channels, classes=out_classes, **kwargs\n",
        "        )\n",
        "        params = smp.encoders.get_preprocessing_params(encoder_name)\n",
        "        self.register_buffer(\"std\", torch.tensor(params[\"std\"]).view(1, 3, 1, 1))\n",
        "        self.register_buffer(\"mean\", torch.tensor(params[\"mean\"]).view(1, 3, 1, 1))\n",
        "        \n",
        "        if config[\"loss\"] == \"jaccard\":\n",
        "            self.loss_fn = smp.losses.JaccardLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "        if config[\"loss\"] == \"dice\":\n",
        "            self.loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "        if config[\"loss\"] == \"focal\":\n",
        "            self.loss_fn = smp.losses.FocalLoss(mode=smp.losses.BINARY_MODE)\n",
        "        \n",
        "\n",
        "    def forward(self, image):\n",
        "        \n",
        "        if(config['corona_path']!=''):\n",
        "          image1,image2=torch.tensor_split(image, 2, dim=1)\n",
        "          image1 = (image1 - self.mean) / self.std\n",
        "          image2 = (image2 - self.mean) / self.std\n",
        "          image=torch.cat((image1, image2), 1)\n",
        "        else:\n",
        "          image = (image - self.mean) / self.std\n",
        "        mask = self.model(image)\n",
        "        return mask\n",
        "\n",
        "    def shared_step(self, batch, stage):\n",
        "        image = batch[0]\n",
        "        assert image.ndim == 4\n",
        "        h, w = image.shape[2:]\n",
        "        assert h % 32 == 0 and w % 32 == 0\n",
        "        mask = batch[1]\n",
        "        assert mask.ndim == 4\n",
        "        assert mask.max() <= 1.0 and mask.min() >= 0\n",
        "        logits_mask = self.forward(image)\n",
        "        loss = self.loss_fn(logits_mask, mask)\n",
        "        self.log_dict({f\"{stage}/loss\": loss.detach().item()},batch_size=config[\"batch_size\"])\n",
        "        prob_mask = logits_mask.sigmoid()\n",
        "        pred_mask = (prob_mask > 0.5).float()  \n",
        "        pred_mask = pred_mask.permute(0,3,1,2)\n",
        "        mask = mask.permute(0,3,1,2)\n",
        "        \n",
        "        tp, fp, fn, tn = smp.metrics.get_stats(pred_mask.long(), mask.long(), mode=\"binary\")\n",
        "        \n",
        "        if stage == \"train\":\n",
        "            self.log_dict({\n",
        "                \"train/batch-IOU-img\":smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro-imagewise\"),\n",
        "                \"train/batch-IOU\":smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro\")\n",
        "            }, prog_bar=True, batch_size=config[\"batch_size\"])\n",
        "\n",
        "        return {\n",
        "            \"loss\": loss,\n",
        "            \"tp\": tp,\n",
        "            \"fp\": fp,\n",
        "            \"fn\": fn,\n",
        "            \"tn\": tn,\n",
        "        }\n",
        "\n",
        "    def shared_epoch_end(self, outputs, stage):\n",
        "        tp = torch.cat([x[\"tp\"] for x in outputs])\n",
        "        fp = torch.cat([x[\"fp\"] for x in outputs])\n",
        "        fn = torch.cat([x[\"fn\"] for x in outputs])\n",
        "        tn = torch.cat([x[\"tn\"] for x in outputs])\n",
        "\n",
        "        per_image_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro-imagewise\")\n",
        "        dataset_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro\")\n",
        "\n",
        "        metrics = {\n",
        "            f\"{stage}/IOU-img\": per_image_iou,\n",
        "            f\"{stage}/IOU\": dataset_iou,\n",
        "        }\n",
        "        \n",
        "        self.log_dict(metrics, prog_bar=True,batch_size=config[\"batch_size\"])\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.shared_step(batch, \"train\")            \n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        return self.shared_epoch_end(outputs, \"train\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self.shared_step(batch, \"valid\")\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        return self.shared_epoch_end(outputs, \"valid\")\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self.shared_step(batch, \"test\")  \n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        return self.shared_epoch_end(outputs, \"test\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=config[\"learning_rate\"]) # 0.00005\n"
      ],
      "metadata": {
        "id": "XS145rxzbrY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_config(name_modello):\n",
        "  config[\"dataset_path\"]=PATH_DATASETS+name_modello\n",
        "  if '1k' in name_modello:\n",
        "    config[\"dim_input\"]='1k'\n",
        "    if('+' in name_modello):\n",
        "      config[\"dataset_path\"]=PATH_DATASETS+'bing_1k/'\n",
        "      config['corona_path']=PATH_DATASETS+'corona_1k/train/sites/'\n",
        "      config['in_channels']=6\n",
        "    else:\n",
        "      config['corona_path']=\"\"\n",
        "      config['in_channels']=3\n",
        "  else:\n",
        "    config[\"dim_input\"]='2k'\n",
        "    if('+' in name_modello):\n",
        "      config['corona_path']=PATH_DATASETS+'corona_2k_filtrato/train/sites/'\n",
        "      config['in_channels']=6\n",
        "      config[\"dataset_path\"]=PATH_DATASETS+'bing_2k_filtrato/'\n",
        "    else:\n",
        "      config['corona_path']=\"\"\n",
        "      config['in_channels']=3"
      ],
      "metadata": {
        "id": "-xl-quxvE3Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.5 Training di ogni modello in base alle sue caratteristiche"
      ],
      "metadata": {
        "id": "gorxvbn7rFnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ogni modello viene allenato in base alle sue caratteristiche. \n",
        "for i in range(len(modelli)):\n",
        "  set_config(modelli[i])\n",
        "  filenames_train = np.asarray(list(sorted(os.listdir(os.path.join(config[\"dataset_path\"], \"train/sites\")))))\n",
        "  print(\"total files:\",len(filenames_train))\n",
        "  indices = np.arange(0,len(filenames_train))\n",
        "  np.random.shuffle(indices)\n",
        "  print(indices)\n",
        "  \n",
        "\n",
        "  images_directory, masks_directory, train_images_filenames,val_images_filenames,test_images_filenames = \n",
        "  load_dataset(config[\"dataset_path\"],config[\"random_seed\"])\n",
        "  train_transform,val_transform=esegui_trasformazioni()\n",
        "  train_dataset = ArcheoDataset(train_images_filenames, images_directory, \n",
        "                                masks_directory,transform=train_transform)\n",
        "  val_dataset = ArcheoDataset(val_images_filenames, images_directory, \n",
        "                              masks_directory, transform=val_transform)\n",
        "  train_loader = DataLoader(train_dataset,batch_size=config[\"batch_size\"], \n",
        "                            shuffle=True,drop_last=True,num_workers=0,)\n",
        "  val_loader = DataLoader(val_dataset,batch_size=config[\"batch_size\"], \n",
        "                          shuffle=False,drop_last=False,num_workers=0,)\n",
        "  model = ArcheoModel(config[\"arch\"],encoder_name=config[\"encoder\"],\n",
        "                      encoder_weights=config[\"weights\"],\n",
        "                      in_channels=config['in_channels'], \n",
        "                      out_classes=1,) #creazione del modello\n",
        "\n",
        "#TRAINING DEL MODELLO\n",
        "\n",
        "  trainer = pl.Trainer(\n",
        "    max_epochs=config[\"epochs\"],\n",
        "    precision=config[\"precision\"],\n",
        "    accelerator=\"gpu\",\n",
        "    logger=pl_loggers.TensorBoardLogger(config[\"checkpoint_path\"]),\n",
        "    log_every_n_steps=1,\n",
        "    enable_progress_bar=True,\n",
        "    callbacks=[RichProgressBar(refresh_rate=1)],\n",
        "   \n",
        "  )\n",
        "  cfg_text = \"\\n\".join([ str(key)+\" : **\"+str(config[key])+\"**  \" for key in config])\n",
        "  print(cfg_text)\n",
        "  trainer.logger.experiment.add_text(tag=\"config\",text_string=cfg_text)\n",
        "\n",
        "  trainer.fit(\n",
        "    model,\n",
        "    train_dataloaders=train_loader, \n",
        "    val_dataloaders=val_loader)\n",
        "  os.rename(PATH_LOG+'lightning_logs/version_0', PATH_LOG+'lightning_logs/'+modelli[i])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5peABn__byW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2 Test di ogni modello\n"
      ],
      "metadata": {
        "id": "THEwd9-GrQwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pytorch_lightning.loggers import tensorboard\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=PATH_LOG"
      ],
      "metadata": {
        "id": "NTsZfXkFdiEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10 test, con diverse trasformazioni, per ogni modello. \n",
        "iou_test_modelli={}\n",
        "for i in range(len(modelli)):\n",
        "  set_config(modelli[i])\n",
        " \n",
        "  filenames_train = np.asarray(list(sorted(os.listdir(\n",
        "      os.path.join(config[\"dataset_path\"], \"train/sites\")))))\n",
        "  print(\"total files:\",len(filenames_train))\n",
        "  indices = np.arange(0,len(filenames_train))\n",
        "  np.random.shuffle(indices)\n",
        "  print(indices)\n",
        "  \n",
        "  \n",
        " \n",
        "  name_ckpt = os.listdir(PATH_LOG+'lightning_logs/'+modelli[i]+'/checkpoints/')[0]\n",
        "  model = ArcheoModel.load_from_checkpoint(arch=config[\"arch\"],\n",
        "                 encoder_name=config[\"encoder\"], \n",
        "                 encoder_weights=config[\"weights\"],\n",
        "                 in_channels=config['in_channels'], \n",
        "                 out_classes=1,\n",
        "                 checkpoint_path=PATH_LOG+'lightning_logs/'+modelli[i]+'/checkpoints/'+name_ckpt)\n",
        "  print(config['dataset_path'])\n",
        "  images_directory, masks_directory, train_images_filenames,\n",
        "  val_images_filenames,test_images_filenames = load_dataset(config[\"dataset_path\"],\n",
        "                                                            config[\"random_seed\"],indices)\n",
        "  \n",
        "  testiou=[]\n",
        "  for j in range(10):\n",
        "    print(\"Risultato \"+str(j)+\" del modello \"+modelli[i])\n",
        "    train_transform,val_transform=esegui_trasformazioni()\n",
        "    test_dataset = ArcheoDataset(test_images_filenames, images_directory, \n",
        "                                 masks_directory, transform=val_transform)\n",
        "    test_loader = DataLoader(test_dataset,batch_size=config[\"batch_size\"],\n",
        "                             shuffle=False,drop_last=False,num_workers=0,)\n",
        "\n",
        "    trainer = pl.Trainer(gpus=1, max_epochs=40,auto_scale_batch_size=\"binsearch\",\n",
        "                         precision=16,accelerator=\"auto\",)\n",
        " \n",
        "    test_metrics = trainer.test(model, dataloaders=test_loader, verbose=True)\n",
        "    testiou.append(test_metrics[0]['test/IOU-img'])\n",
        "  iou_test_modelli[modelli[i]]=testiou"
      ],
      "metadata": {
        "id": "pYBPlPw9BTOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stampo le statistiche per ogni modello (mean,min,max,std)\n",
        "for i in modelli:\n",
        "  x=np.array(iou_test_modelli[i])\n",
        "  print(\"Le statistiche sul test set per il modello \"+i+\" sono:\")\n",
        "  print(\"media:\"+str(round(x.mean(),4))+\" | min:\"+str(round(x.min(),4))\n",
        "    +\" | max:\"+str(round(x.max(),4))+\" | std:\"+str(round(x.std(),4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm0RObDA_BPA",
        "outputId": "cb33e9a8-7d60-453c-caab-dafaeeebc366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le statistiche sul test set per il modello bing_1k sono:\n",
            "media:0.7417 | min:0.7356 | max:0.7468 | std:0.0038\n",
            "Le statistiche sul test set per il modello bing_1k_filtrato sono:\n",
            "media:0.781 | min:0.7689 | max:0.788 | std:0.0054\n",
            "Le statistiche sul test set per il modello bing+corona_1k sono:\n",
            "media:0.7406 | min:0.7347 | max:0.746 | std:0.0039\n",
            "Le statistiche sul test set per il modello bing+corona_2k_filtrato sono:\n",
            "media:0.8345 | min:0.8312 | max:0.8376 | std:0.0018\n",
            "Le statistiche sul test set per il modello bing_2k sono:\n",
            "media:0.7977 | min:0.7929 | max:0.8031 | std:0.0034\n",
            "Le statistiche sul test set per il modello bing_2k_filtrato sono:\n",
            "media:0.8154 | min:0.8087 | max:0.8223 | std:0.0035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3 Valutazione Modelli"
      ],
      "metadata": {
        "id": "nxyJKE2ZVQEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Caricamento dei csv contenenti coordinate siti"
      ],
      "metadata": {
        "id": "WDsztoQgZnBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "namesite2Centroid={}\n",
        "nameneg2Centroid={}\n",
        "namemaysan2Centroid={}\n",
        "name2min={}\n",
        "\n",
        "\n",
        "with open('trainset1000.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "      namesite2Centroid[row[2]]=[row[3],row[4]]\n",
        "      \n",
        "\n",
        "with open('negs1000.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        nameneg2Centroid[row[5]]=[row[3],row[4]]\n",
        "\n",
        "\n",
        "with open('maysan1000.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        namemaysan2Centroid[row[1]]=[row[2],row[3]]\n",
        "\n"
      ],
      "metadata": {
        "id": "0We15_RvVWOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2 Carico il dataset applicandogli trasformazioni prestabilite\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TZ31iVC-ZvJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ArcheoDatasetModify(Dataset):\n",
        "    def __init__(self, images_filenames, images_directory, masks_directory):\n",
        "        self.images_filenames = images_filenames\n",
        "        self.images_directory = images_directory\n",
        "        self.masks_directory = masks_directory\n",
        "     \n",
        "    def __len__(self):\n",
        "        return len(self.images_filenames)\n",
        "\n",
        "    def __getitem__(self, idx, verbose=False):\n",
        "      image_filename = self.images_filenames[idx]+'.jpg'\n",
        "      image_path = os.path.join(self.images_directory, image_filename)\n",
        "      mask_path = os.path.join(self.masks_directory, \n",
        "                               image_filename.replace(\".jpg\", \".png\"))\n",
        "        \n",
        "      image = np.array(Image.open(image_path))#.convert(\"RGB\"))\n",
        "      image = Image.open(image_path)\n",
        "      # masks are flipped because of qgis\n",
        "      mask = ~np.array(Image.open(mask_path).convert(\"L\")) \n",
        "      mask = mask.astype(\"float\")\n",
        "      mask[mask > 0.0] = 1.0\n",
        "      mask = np.expand_dims(mask, -1)\n",
        "      x_minore=int(name2tras[image_filename[:-4]][0])\n",
        "      y_minore=int(name2tras[image_filename[:-4]][1])\n",
        "      if(config['corona_path']!=''):     \n",
        "        path_corona=config['corona_path']\n",
        "        image_path_corona=os.path.join(path_corona, image_filename)\n",
        "        image_corona =np.array(Image.open(image_path_corona))\n",
        "        image_corona = Image.open(image_path_corona)\n",
        "  \n",
        "        trasformazione = A.Compose([\n",
        "            A.Crop(x_min=x_minore, y_min=y_minore, \n",
        "                   x_max=x_minore+1024, y_max=y_minore+1024,p=1.0),\n",
        "            A.Resize(512,512),\n",
        "            A.pytorch.ToTensorV2()],additional_targets={'image_corona': 'image'})\n",
        "        transformed = trasformazione(image=np.asarray(image),\n",
        "                                     image_corona=np.asarray(image_corona),\n",
        "                                     mask=np.asarray(mask))\n",
        "        image_corona=transformed[\"image_corona\"]\n",
        "        image = transformed[\"image\"]\n",
        "        image=torch.cat((image, image_corona), 0)\n",
        "      \n",
        "      else:\n",
        "        trasformazione = A.Compose([\n",
        "            A.Crop(x_min=x_minore, y_min=y_minore, \n",
        "                   x_max=x_minore+1024, y_max=y_minore+1024,p=1.0),\n",
        "            A.Resize(512,512),\n",
        "            A.pytorch.ToTensorV2()])\n",
        "        transformed = trasformazione(image=np.asarray(image),\n",
        "                                     mask=np.asarray(mask))\n",
        "        image = transformed[\"image\"]\n",
        "\n",
        "      mask = transformed[\"mask\"].permute(2,0,1)\n",
        "      return image, mask, image_filename"
      ],
      "metadata": {
        "id": "g4tHQ6NpYgnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.3 Salvataggio delle singole predizioni"
      ],
      "metadata": {
        "id": "uSN2bOPoZ_1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import gaussian_filter\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#data la predizione,viene applicato un cutoff\n",
        "def stampa_predizioni_cutoff(ibatch,ipr_masks_11,num,nome_modello,val):\n",
        "    for i,(image, gt_mask, masks_11, fn) in enumerate(zip(ibatch[0], ibatch[1], \n",
        "                                                          ipr_masks_11, ibatch[2])):\n",
        "      masks_11 = masks_11.numpy().squeeze()\n",
        "      # cutoff\n",
        "      cf = masks_11.copy()\n",
        "      cf = gaussian_filter(cf, sigma=5)\n",
        "      cf = ((cf + 0.5)**2) - 0.5\n",
        "      cf[cf<=val] = 0.0\n",
        "      cf[cf>val] = 1.0\n",
        "\n",
        "\n",
        "      plt.imsave('/output/'+nome_modello+'/pred_siti_tronc'+\n",
        "                 str(val)+'/'+ fn[:-4]+'.png',cf, cmap=\"magma\", vmin=0.0, vmax=1.0)\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "DvYGKQorZkSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.4 Date le predizioni per ogni sito, creo i tif e gli shapefile corrispondenti"
      ],
      "metadata": {
        "id": "izYHcVUK2fqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dato la predizione, viene creato il tif associato. \n",
        "import rasterio\n",
        "def createTif(ovest,sud,est,nord,patin,patout):\n",
        "  dataset = rasterio.open(patin, 'r')\n",
        "  bands = [1, 2, 3]\n",
        "  data = dataset.read(bands)\n",
        "  transform = rasterio.transform.from_bounds(ovest, sud, est, nord, data.shape[2], data.shape[1])\n",
        "  crs = {'init': 'epsg:3857'}\n",
        "\n",
        "  with rasterio.open(patout, 'w', driver='GTiff',\n",
        "                   width=data.shape[2], height=data.shape[1],\n",
        "                   count=3, dtype=data.dtype, nodata=0,\n",
        "                   transform=transform, crs=crs) as dst:\n",
        "      dst.write(data, indexes=bands)"
      ],
      "metadata": {
        "id": "tWXX71yiiSPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ricostruisco la predizione usando le trasformazioni salvate in precedenza.\n",
        "def convertImageToTif(nome_modello,val_tronc,path_pred,path_pred_total,path_tif):\n",
        "  for i in range(len(test_images_filenames)):\n",
        "    \n",
        "    im_sfondo=Image.open('black_2048.jpg')\n",
        "    im_sito = Image.open(path_pred+test_images_filenames[i]+'.png')\n",
        "    \n",
        "    newsize = (1024, 1024)\n",
        "    im_sito = im_sito.resize(newsize)\n",
        "    x_min=int(name2tras[test_images_filenames[i]][0])\n",
        "    x_max=(int(name2tras[test_images_filenames[i]][0])+1024)\n",
        "    y_min=int(name2tras[test_images_filenames[i]][1])\n",
        "    y_max=(int(name2tras[test_images_filenames[i]][1])+1024)\n",
        "    im_sfondo.paste(im_sito, (x_min, y_min,x_max,y_max))\n",
        "    im_sfondo = im_sfondo.save(path_pred_total+test_images_filenames[i]+'.png')\n",
        "    if(\"neg\" in test_images_filenames[i]):\n",
        "      x_centroide=float(nameneg2Centroid[test_images_filenames[i]][0])\n",
        "      y_centroide=float(nameneg2Centroid[test_images_filenames[i]][1])\n",
        "    else:\n",
        "      x_centroide=float(namesite2Centroid[test_images_filenames[i]][0])\n",
        "      y_centroide=float(namesite2Centroid[test_images_filenames[i]][1])\n",
        "    ovest=x_centroide-1000\n",
        "    est=x_centroide+1000\n",
        "    sud=y_centroide-1000\n",
        "    nord=y_centroide+1000\n",
        "    createTif(ovest=ovest, sud=sud, est=est, nord=nord,\n",
        "              patin=path_pred_total+test_images_filenames[i]+'.png',\n",
        "              patout=path_tif+test_images_filenames[i]+\".tif\")\n",
        "\n"
      ],
      "metadata": {
        "id": "R5sQpAQAicdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prende i tif files e restituisce gli shape files\n",
        "import os\n",
        "import subprocess\n",
        "from tqdm.auto import tqdm\n",
        "from gdal import gdal_contour\n",
        "\n",
        "def convertTifToShape(tif_path,shape_path):\n",
        "  filenames = os.listdir(tif_path)\n",
        "  print(len(filenames)) #521\n",
        "  for f in tqdm(filenames):\n",
        "    print(f[:-4])\n",
        "    subprocess.run([\"gdal_contour.exe\",\"-i\",\"128\",\"-p\",tif_path+f,shape_path+f[:-4]+\".shp\"],\n",
        "                   capture_output=True,shell=True,check=False)"
      ],
      "metadata": {
        "id": "yjwqUkkaxPXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prende in input il file csv con le trasformazioni per ogni sito, \n",
        "#ritorna i nomi dei siti e un dizionario nome_sito -> trasformazioni\n",
        "def crea_trasformazione(path_csv):\n",
        "  test_sites=[]\n",
        "  name2min={}\n",
        "  count=0\n",
        "  with open(path_csv, 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in (reader):\n",
        "        if(count!=0):\n",
        "          test_sites.append(row[1])\n",
        "          name2min[row[1]]=[row[2],row[3]]\n",
        "        count+=1\n",
        "    \n",
        "  return test_sites,name2min"
      ],
      "metadata": {
        "id": "uZUWOQoGl9T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.5 Dati gli shapefile in input e restituisco un geojson contenente per ogni sito TP,TN,FP,FN"
      ],
      "metadata": {
        "id": "-0IVHb-nJXQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import geopandas as geopd\n",
        "from tqdm.auto import tqdm\n",
        "from shapely.geometry.multipolygon import MultiPolygon\n",
        "\n",
        "#Assegna ad ogni sito tp,tn,fp,fn in base all'intersezione della forma predetta \n",
        "#con la forma originale\n",
        "def test_for_intersection(site_id,path,verbose=False):\n",
        "    ### get shape for the original site\n",
        "    sites = geopd.read_file(PATH_SHAPE).to_crs(\"EPSG:3857\") # project to web-mercator\n",
        "    a = sites[sites.entry_id == site_id][[\"entry_id\",\"geometry\"]]\n",
        "    \n",
        "    if verbose: print('Loading Contours')\n",
        "    b = geopd.read_file(path+site_id+\".shp\").set_crs(\"EPSG:3857\")\n",
        "    b.geometry = b.geometry.convex_hull\n",
        "    b[\"entry_id\"] = \"pred\"\n",
        "    \n",
        "    if verbose: \n",
        "        print(\"number of features:\",len(b))\n",
        "        print(b)\n",
        "        \n",
        "    if len(b) > 1: # if there is more than one shape\n",
        "        b[\"geometry\"] = MultiPolygon([feature for feature in b[\"geometry\"]])\n",
        "        b = b[:1].copy()\n",
        "        if verbose: \n",
        "            print(b)\n",
        "            b.plot()\n",
        "    # negs should have no geometry\n",
        "    if len(b) == 0 and site_id.startswith(\"neg\"):\n",
        "        if verbose: print(\"good neg\")\n",
        "        return \"TN\",site_id,None\n",
        "    \n",
        "    # if neg has geometry then FP\n",
        "    elif len(b) > 0 and site_id.startswith(\"neg\"):\n",
        "        if verbose: print(\"false positive\")\n",
        "        return \"FP\",site_id,b.iloc[0][\"geometry\"] #False\n",
        "    \n",
        "    # if no geometry and not neg then FN. use a.geometry for use in QGIS\n",
        "    elif len(b) == 0 and not site_id.startswith(\"neg\"):\n",
        "        if verbose: print(\"false negative\")\n",
        "        return \"FN\",site_id, a.iloc[0][\"geometry\"]\n",
        "    \n",
        "    # compute intersection\n",
        "    if ~b.iloc[0].geometry.is_valid:\n",
        "        b.geometry = b.geometry.buffer(0)\n",
        "    intersects = a.iloc[0][\"geometry\"].intersects(b.iloc[0][\"geometry\"])\n",
        "    if verbose:\n",
        "        c = pd.concat([a,b])\n",
        "        # print(c)\n",
        "        c.plot(column=\"entry_id\",legend=True,figsize=(5,5),cmap=\"Set3\")\n",
        "        print(\"INTERSECTION: \", intersects)\n",
        "        \n",
        "    if intersects: # right geometry\n",
        "        return \"TP\",site_id,b.iloc[0][\"geometry\"]\n",
        "    else: # wrong geometry\n",
        "        return \"FP\",site_id,b.iloc[0][\"geometry\"]"
      ],
      "metadata": {
        "id": "NFGZZCWUGr7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as geopd\n",
        "#prende in input gli shapefile dei siti e ritorna un geojson \n",
        "#contenente id,nome sito, geometria e valore tra tp,tn,fp,fn\n",
        "def convertShapeToGeojson(testset,path_in,path_out):\n",
        " res = {\"index\":[],\"entry_id\":[],\"geometry\":[],\"cat\":[],}\n",
        " indice=0\n",
        " for sito in testset:\n",
        "    cat,eid,geom = test_for_intersection(sito,path_in,verbose=False)\n",
        "    res[\"index\"].append(indice)\n",
        "    res[\"entry_id\"].append(eid)\n",
        "    res[\"geometry\"].append(geom)\n",
        "    res[\"cat\"].append(cat)\n",
        "    indice+=1\n",
        " res_df = geopd.GeoDataFrame(res)\n",
        " res_df = res_df.set_index(\"index\")\n",
        " res_df.to_file(path_out, driver='GeoJSON',crs=\"EPSG:3857\")  "
      ],
      "metadata": {
        "id": "WqIYsriiHX9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.6 Main"
      ],
      "metadata": {
        "id": "hmUHRD95J-ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelli_da_comparare=['bing+corona_2k_filtrato','bing_2k_filtrato']\n",
        "PATH_SHAPE='/shapefiles/site_shape/vw_site_survey_poly.shp'\n",
        "for modello in modelli_da_comparare:\n",
        "  PATH_OUTPUT='output/'+modello+'/'\n",
        "  set_config(modello)\n",
        "  name_ckpt = os.listdir(PATH_LOG+'lightning_logs/'+modello+'/checkpoints/')[0]\n",
        "  model= ArcheoModel.load_from_checkpoint(arch=config[\"arch\"],\n",
        "                 encoder_name=config[\"encoder\"], \n",
        "                 encoder_weights=config[\"weights\"],\n",
        "                 in_channels=config['in_channels'], out_classes=1,\n",
        "                 checkpoint_path=PATH_LOG+'lightning_logs/'+modello+'/checkpoints/'+name_ckpt)\n",
        "  random.seed(config[\"random_seed\"])\n",
        "  np.random.seed(config[\"random_seed\"])\n",
        "  torch.manual_seed(config[\"random_seed\"])\n",
        "  test_images_filenames,name2tras=crea_trasformazione('trasformazioni_modello.csv')\n",
        "  images_directory=config[\"dataset_path\"]+'/train/sites'\n",
        "  masks_directory=config[\"dataset_path\"]+'/train/masks'\n",
        "  test_dataset = ArcheoDatasetModify(test_images_filenames, \n",
        "                                     images_directory, \n",
        "                                     masks_directory)\n",
        "  test_loader = DataLoader(test_dataset,batch_size=config[\"batch_size\"],\n",
        "                           shuffle=False,drop_last=False,num_workers=0,)\n",
        "\n",
        "  print(len(test_images_filenames))\n",
        "  it = iter(test_loader)\n",
        "\n",
        "\n",
        "  for j in range(len(it)):\n",
        "    batch = next(it)\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      logits = model(batch[0])\n",
        "    pr_masks = logits.sigmoid()\n",
        "    stampa_predizioni_cutoff(batch,pr_masks,j,modello,0.2)\n",
        "    stampa_predizioni_cutoff(batch,pr_masks,j,modello,0.5)\n",
        "\n",
        "  convertImageToTif(modello,0.2,PATH_OUTPUT+'pred_siti_tronc0.2/',\n",
        "                    PATH_OUTPUT+'pred_siti_centro_tronc0.2/',PATH_OUTPUT+'tif_0.2/')\n",
        "  convertImageToTif(modello,0.5,PATH_OUTPUT+'pred_siti_tronc0.5/',\n",
        "                    PATH_OUTPUT+'pred_siti_centro_tronc0.5/',PATH_OUTPUT+'tif_0.5/')\n",
        "\n",
        "  convertTifToShape(PATH_OUTPUT+'tif_0.2/',PATH_OUTPUT+'shape_0.2/')\n",
        "  convertTifToShape(PATH_OUTPUT+'tif_0.5/',PATH_OUTPUT+'shape_0.5/')\n",
        "\n",
        "  convertShapeToGeojson(test_images_filenames,PATH_OUTPUT+'shape_0.2/',PATH_OUTPUT+'preds02.geojson')\n",
        "  convertShapeToGeojson(test_images_filenames,PATH_OUTPUT+'shape_0.5/',PATH_OUTPUT+'preds05.geojson')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uB86uU4ZehpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Analisi Risultati"
      ],
      "metadata": {
        "id": "IJaH3-WzNyMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Calcolo della matrice di confusione, in modo automatico e adattato"
      ],
      "metadata": {
        "id": "T_0SyTrCU8Uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcola_matrix(preds):\n",
        "  tp= preds[preds.cat == \"TP\"]['entry_id'].shape[0]\n",
        "  tn= preds[preds.cat == \"TN\"]['entry_id'].shape[0]\n",
        "  fp= preds[preds.cat == \"FP\"]['entry_id'].shape[0]\n",
        "  fn= preds[preds.cat == \"FN\"]['entry_id'].shape[0]\n",
        "\n",
        "  matrix=[tp,tn,fp,fn]\n",
        "\n",
        "  # sono siti non visibili, quindi classificati erroneamente come tn\n",
        "  fn2tn = preds[(preds.cat == \"FN\")&(preds.correction == \"TN\")]['entry_id'].shape[0]\n",
        "\n",
        "  sites_inside_ot=preds[(preds.notes.str.contains('INSIDE OTHER',na=False)) ].shape[0]\n",
        "\n",
        "  #siti non visibili e il modello ne trova un altro esistente\n",
        "  fp2tp = preds[\n",
        "    (preds.cat == \"FP\")& ((preds.notes.str.contains('NV',na=False))| \n",
        "                        (preds.notes.str.contains('NOT VISIBLE',na=False)) |\n",
        "                        (preds.notes.str.contains('NOT VISIBILE',na=False)) |\n",
        "                        (preds.entry_id.str.contains('neg',na=False)))&\n",
        "                        (preds.notes.str.contains('INSIDE OTHER',na=False))].shape[0]\n",
        "\n",
        "  #siti visibili e il modello ne trova un altro esistente \n",
        "  fp2fn=sites_inside_ot-fp2tp\n",
        "\n",
        "  tn_a = tn + fn2tn + fp2tp\n",
        "  fn_a = fn - fn2tn + fp2fn\n",
        "  tp_a = tp + (fp2tp+fp2fn)\n",
        "  fp_a = fp - (fp2tp+fp2fn)\n",
        "\n",
        "  matrix_adj=[tp_a,tn_a,fp_a,fn_a]\n",
        "  \n",
        "  return(matrix,matrix_adj)\n",
        "\n"
      ],
      "metadata": {
        "id": "s9g4FjnPJJaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mi stampo le statistiche in termini di valori della matrice di confusione oltre a\n",
        "# precisione,recall.\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "def stampa_stats(cm,cm_adj,bing):\n",
        "  print('--------------------------------------------')\n",
        "  if(bing):\n",
        "    print(\"Stats Modello Bing 2k filtrato:\")\n",
        "  else:\n",
        "    print(\"Stats Modello Bing + Corona 2k filtrato:\")\n",
        "\n",
        "  print('---')\n",
        "\n",
        "  print(\"Valutazione automatica:\")\n",
        "  print(\"TP: \"+str(cm[0])+\" TN: \"+str(cm[1])+\" FP: \"+str(cm[2])+\" FN: \"+str(cm[3]))\n",
        "  print(\"Accuracy: \",round((cm[0]+cm[1])/(cm[0]+cm[1]+cm[2]+cm[3]),4))\n",
        "  print(\"Recall: \",round(cm[0]/(cm[0]+cm[3]),4))\n",
        "\n",
        "  print('---')\n",
        "\n",
        "  print(\"Valutazione manuale:\")\n",
        "  print(\"TP: \"+str(cm_adj[0])+\" TN: \"+str(cm_adj[1])+\" FP: \"+str(cm_adj[2])+\" FN: \"+str(cm_adj[3]))\n",
        "  print(\"Accuracy: \",round((cm_adj[0]+cm_adj[1])/(cm_adj[0]+cm_adj[1]+cm_adj[2]+cm_adj[3]),4))\n",
        "  print(\"Recall: \",round(cm_adj[0]/(cm_adj[0]+cm_adj[3]),4))\n",
        "\n",
        "  print('--------------------------------------------')"
      ],
      "metadata": {
        "id": "A_DrUrJ0ZsGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_GDMmUXk-q5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "391f0ee3-9a46-490b-ff09-fa8f7a7c5a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n",
            "Stats Modello Bing 2k filtrato:\n",
            "---\n",
            "Valutazione automatica:\n",
            "TP: 228 TN: 98 FP: 70 FN: 125\n",
            "Accuracy:  0.6257\n",
            "Recall:  0.6459\n",
            "---\n",
            "Valutazione manuale:\n",
            "TP: 258 TN: 185 FP: 40 FN: 68\n",
            "Accuracy:  0.804\n",
            "Recall:  0.7914\n",
            "--------------------------------------------\n",
            "--------------------------------------------\n",
            "Stats Modello Bing + Corona 2k filtrato:\n",
            "---\n",
            "Valutazione automatica:\n",
            "TP: 209 TN: 104 FP: 57 FN: 151\n",
            "Accuracy:  0.6008\n",
            "Recall:  0.5806\n",
            "---\n",
            "Valutazione manuale:\n",
            "TP: 239 TN: 197 FP: 27 FN: 88\n",
            "Accuracy:  0.7913\n",
            "Recall:  0.7309\n",
            "--------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import geopandas as geopd\n",
        "PATH_GEOJSON_BING='/output/bing_2k_filtrato/preds05.geojson'\n",
        "PATH_GEOJSON_CORONA='/output/bing+corona_2k_filtrato/preds05.geojson'\n",
        "preds_bing = geopd.read_file(PATH_GEOJSON_BING).sort_values(\"index\").reset_index(drop=True)\n",
        "preds_corona = geopd.read_file(PATH_GEOJSON_CORONA).sort_values(\"index\").reset_index(drop=True)\n",
        "\n",
        "\n",
        "cm_bing,cm_bing_adj=calcola_matrix(preds_bing)\n",
        "stampa_stats(cm_bing,cm_bing_adj,bing=True)\n",
        "\n",
        "\n",
        "cm_corona,cm_corona_adj=calcola_matrix(preds_corona)\n",
        "stampa_stats(cm_corona,cm_corona_adj,bing=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5 Area di selezione"
      ],
      "metadata": {
        "id": "_OVuUTDUGFpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.1 Crea le predizioni per ogni tessera"
      ],
      "metadata": {
        "id": "ckmrJv7FV3jQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_MAYSAN_DATASET='/datasets/maysan_sel_tile/'\n",
        "PATH_MAYSAN_OUTPUT='/output/maysan_sel_area/'\n",
        "PATH_MODEL_USED=PATH_LOG+'lightning_logs/bing+corona_2k_filtrato/checkpoints/epoch=19-step=2600.ckpt'"
      ],
      "metadata": {
        "id": "GAwuOOJuMSdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stampa_predizioni(ibatch,ipr_masks_11,num,patout):\n",
        "  for i,(image, gt_mask, masks_11, fn) in enumerate(zip(ibatch[0], ibatch[1], ipr_masks_11, ibatch[2])):\n",
        "\n",
        "    masks_11 = masks_11.numpy().squeeze()\n",
        "    plt.imsave(patout+'pred_magma_v1/'+ fn[:-4]+'.png',masks_11,cmap=\"magma\", vmin=0.0, vmax=1.0)\n",
        "    plt.imsave(patout+'pred_grey_v1/'+ fn[:-4]+'.png',masks_11,cmap=\"Greys\", vmin=0.0, vmax=1.0)\n",
        "   "
      ],
      "metadata": {
        "id": "Ymw6DzvxvQXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames_test_maysan = np.asarray(list(sorted(os.listdir(PATH_MAYSAN_DATASET+'sites'))))\n",
        "config['corona_path']=PATH_MAYSAN_DATASET+'corona_v1/'\n",
        "transform_maysan=A.Compose([A.Resize(512, 512),A.pytorch.ToTensorV2(),],\n",
        "                           additional_targets={'image_corona': 'image'})\n",
        "test_dataset_maysan = ArcheoDataset(filenames_test_maysan, PATH_MAYSAN_DATASET+'sites/', \n",
        "                                    PATH_MAYSAN_DATASET+'masks/', transform=transform_maysan)\n",
        "test_loader_maysan = DataLoader(test_dataset_maysan,batch_size=config[\"batch_size\"], \n",
        "                                shuffle=False,drop_last=False,num_workers=0,)\n",
        "model = ArcheoModel.load_from_checkpoint(arch=config[\"arch\"],\n",
        "                 encoder_name=config[\"encoder\"], \n",
        "                 encoder_weights=config[\"weights\"],\n",
        "                 in_channels=6, out_classes=1,checkpoint_path=PATH_MODEL_USED)\n",
        "\n",
        "random.seed(config[\"random_seed\"])\n",
        "np.random.seed(config[\"random_seed\"])\n",
        "torch.manual_seed(config[\"random_seed\"])\n",
        "\n",
        "it_maysan=iter(test_loader_maysan)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "for i in range(len(it_maysan)):\n",
        "  batch = next(it_maysan)\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    logits = model(batch[0])\n",
        "  pr_masks = logits.sigmoid()\n",
        "  stampa_predizioni(batch,pr_masks,i,PATH_MAYSAN_OUTPUT)\n"
      ],
      "metadata": {
        "id": "0agFYumlGUnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.2 Assembla l'immagine totale dell'area di selezione"
      ],
      "metadata": {
        "id": "UjqZMMcmWAnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crea_righe(imm_size,l_x,l_y,fn,resize=False,num_res=256,format=\".png\"):\n",
        "  righe=[]\n",
        "  altezza=1\n",
        "  if(resize==True):\n",
        "    image_tot = Image.open(fn+\"1\"+format).resize((num_res,num_res))\n",
        "  else:\n",
        "    image_tot = Image.open(fn+\"1\"+format)\n",
        "  for i in range(2,l_x*l_y+1):\n",
        "    if((i-1)%l_x==0):\n",
        "      if(resize==True):\n",
        "        image_tot=Image.open(fn+str(i)+format).resize((num_res,num_res))\n",
        "      else:\n",
        "        image_tot=Image.open(fn+str(i)+format)\n",
        "    else:\n",
        "      if(resize==True):\n",
        "        image_open=Image.open(fn+str(i)+format).resize((num_res,num_res))\n",
        "      else:\n",
        "        image_open=Image.open(fn+str(i)+format)\n",
        "      new_image = Image.new('RGB',(imm_size*l_x, imm_size))\n",
        "      new_image.paste(image_tot,(0,0))\n",
        "      posizione=i%l_x\n",
        "      if(posizione==0):\n",
        "        posizione=l_x\n",
        "      new_image.paste(image_open,(imm_size*(posizione-1),((altezza-1)*image_open.size[1])))\n",
        "      image_tot=new_image\n",
        "      if(posizione==l_x):righe.append(image_tot)\n",
        "  return righe\n",
        "\n",
        "def crea_immagine(righ,dim,l_x,l_y,nome):\n",
        "  imm_totale = Image.new('RGB',(l_x*dim, l_y*dim))\n",
        "  x=-dim\n",
        "  for i in reversed(range(len(righ))):\n",
        "    x+=dim\n",
        "    imm_totale.paste(righ[i],(0,x))\n",
        "  imm_totale.save(PATH_MAYSAN_OUTPUT+nome+'.jpg')"
      ],
      "metadata": {
        "id": "qq2DYnpepMBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "f = open('coor_maysan_1000.json')\n",
        "data = json.load(f)\n",
        "spost=data[1]['cx']-data[0]['cx']\n",
        "ovest=int(data[0]['cx']-spost/2)\n",
        "sud=int(data[0]['cy']-spost/2)\n",
        "nord=int(data[len(data)-1]['cy']+(spost/2))\n",
        "num_righe=int((nord-sud)/spost)\n",
        "num_colonne=int(len(data)/num_righe)\n",
        "est=int(data[num_colonne-1]['cx']+spost/2)\n",
        "\n",
        "\n",
        "righe=crea_righe(512,num_colonne,num_righe,PATH_MAYSAN_OUTPUT+'pred_magma_v1/')\n",
        "righe1=crea_righe(512,num_colonne,num_righe,PATH_MAYSAN_OUTPUT+'pred_grey_v1/')\n",
        "crea_immagine(righe,512,num_colonne,num_righe,\"imm_tot_magma_v1\")\n",
        "crea_immagine(righe1,512,num_colonne,num_righe,\"imm_tot_grey_v1\")\n",
        "createTif(ovest,sud,est,nord,PATH_MAYSAN_OUTPUT+\"imm_tot_magma_v1.jpg\",\n",
        "          PATH_MAYSAN_OUTPUT+\"imm_tot_magma_v1.tif\")\n",
        "createTif(ovest,sud,est,nord,PATH_MAYSAN_OUTPUT+\"imm_tot_grey_v1.jpg\",\n",
        "          PATH_MAYSAN_OUTPUT+\"imm_tot_grey_v1.tif\")\n",
        "\n"
      ],
      "metadata": {
        "id": "VmCZ89aHsdBQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}